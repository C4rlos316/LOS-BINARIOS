---
description: 
auto_execution_mode: 3
---

# (Step 2: Agentes de Auto-Mejora)

**Asistente:** ActÃºa como mi Programador Experto en Python. Vamos a modificar `console_agent.py` (nuestro "Step 1") para implementar el "Step 2".

**Objetivo:** Integrar el ciclo de feedback (ğŸ‘/ğŸ‘) en el bucle principal. Crearemos dos nuevas funciones (agentes) que se llamarÃ¡n con el feedback del usuario para *escribir* en la base de datos `kavak_memory.db`.

**Reglas de CodificaciÃ³n (Â¡MUY IMPORTANTE!):**
1.  **Anti-Proxy:** El `llm` principal ya estÃ¡ configurado con clientes `httpx` personalizados. Las nuevas funciones de agente (Resumidor y Optimizador) **deben** recibir esta instancia `llm` ya configurada para evitar errores de proxy.
2.  **Stack:** Sigue usando `langchain==0.3.7`, `openai==1.54.0` y `sqlite3`.

---

### Instrucciones del "Step 2":

Modifica el archivo `console_agent.py` existente.

#### 1. Modificar Archivo: `console_agent.py`

**Instrucciones:**
* **Conservar Imports:** MantÃ©n todos los imports existentes (`os`, `sqlite3`, `dotenv`, `langchain`, `httpx`).
* **Conservar ConfiguraciÃ³n Anti-Proxy:** MantÃ©n intacta la limpieza de variables de entorno (`os.environ.pop...`).
* **Conservar Funciones de Lectura:** MantÃ©n intactas las funciones `get_db_connection()`, `get_all_rules()`, `get_user_memory()` y `build_system_prompt()`.

* **Nueva FunciÃ³n: `save_user_memory(user_id, chat_history_list, llm_instance)` (El Agente Resumidor)**
    * **Objetivo:** Genera y guarda un resumen de la conversaciÃ³n en `user_memory`.
    * **Instrucciones:**
        * Define la funciÃ³n para que acepte `user_id`, `chat_history_list` (la lista de mensajes) y `llm_instance` (el LLM ya configurado).
        * Define el `MEMORY_PROMPT`: `"Eres un agente resumidor. Basado en esta conversaciÃ³n, extrae el interÃ©s clave, problema o intenciÃ³n del usuario en una sola frase concisa para usarla como memoria a futuro."`
        * Crea una lista de mensajes para el "Resumidor" que combine el `MEMORY_PROMPT` con el historial de chat (`chat_history_list`).
        * **IMPORTANTE:** Llama al LLM usando la instancia pasada: `response = llm_instance.invoke(mensajes_para_resumen)`.
        * ObtÃ©n el resumen: `summary_text = response.content`.
        * ConÃ©ctate a la BD (usa `get_db_connection()`).
        * Ejecuta `INSERT INTO user_memory (user_id, context) VALUES (?, ?)`, pasando `(user_id, summary_text)`.
        * Haz `conn.commit()` y `conn.close()`.
        * Imprime un mensaje: `print("\n[Sistema: ğŸ‘ Memoria guardada exitosamente.]")`.

* **Nueva FunciÃ³n: `optimize_prompt_rule(chat_history_list, llm_instance)` (El Agente Optimizador)**
    * **Objetivo:** Genera y guarda una nueva regla de prompt en `prompt_rules`.
    * **Instrucciones:**
        * Define la funciÃ³n para que acepte `chat_history_list` y `llm_instance`.
        * Extrae la Ãºltima pregunta (el Ãºltimo `HumanMessage`) y la Ãºltima respuesta (el Ãºltimo `AIMessage`) del `chat_history_list`.
        * Define el `OPTIMIZER_PROMPT` (un string largo):
            ```
            Eres un 'Optimizador de Prompts' experto. La siguiente respuesta del bot a la pregunta del usuario fue marcada como 'No Ãštil'.
            
            Tu tarea es analizar el fallo y generar una 'REGLA:' corta y especÃ­fica para el prompt del sistema que ayude a bots futuros a evitar este error.
            La regla debe ser accionable y clara.
            
            Ejemplo de Regla: 'REGLA: Si el usuario pregunta por garantÃ­a, siempre mencionar la garantÃ­a mecÃ¡nica de 3 meses.'
            
            ---
            Pregunta del Usuario que fallÃ³: {pregunta_usuario}
            Respuesta del Bot que fallÃ³: {respuesta_bot}
            ---
            
            Genera la nueva REGLA:
            ```
        * Formatea el `OPTIMIZER_PROMPT` con la pregunta y respuesta extraÃ­das.
        * **IMPORTANTE:** Llama al LLM: `response = llm_instance.invoke([HumanMessage(content=prompt_formateado)])`.
        * ObtÃ©n la nueva regla: `new_rule_text = response.content`.
        * ConÃ©ctate a la BD (usa `get_db_connection()`).
        * Ejecuta `INSERT INTO prompt_rules (rule_text) VALUES (?)`, pasando `(new_rule_text,)`.
        * Haz `conn.commit()` y `conn.close()`.
        * Imprime un mensaje: `print("\n[Sistema: ğŸ‘ Nueva regla aprendida y guardada.]")`.

* **Modificar FunciÃ³n `main()` (El Bucle Principal):**
    * **Conservar ConfiguraciÃ³n:** MantÃ©n toda la configuraciÃ³n inicial dentro de `main()` (peticiÃ³n de `user_id`, clientes `httpx`, inicializaciÃ³n de `llm`, `build_system_prompt`, etc.).
    * **Modificar Bucle `while True`:**
        * Localiza el final del bloque `try...except`, justo despuÃ©s de `chat_history.append(AIMessage(content=ai_response_content))`.
        * **Inmediatamente despuÃ©s**, inserta un nuevo **bucle de feedback**:
        * Imprime en consola: `print("\nÂ¿Esta respuesta fue Ãºtil? ( ğŸ‘ / ğŸ‘ / 'siguiente' para continuar )")`
        * Captura el feedback: `feedback = input("Tu feedback: ").strip().lower()`
        * Usa un `if/elif/else`:
            * `if feedback == 'ğŸ‘'`:
                * Llama a `save_user_memory(user_id, chat_history, llm)`
            * `elif feedback == 'ğŸ‘'`:
                * Llama a `optimize_prompt_rule(chat_history, llm)`
            * `elif feedback == 'siguiente' or feedback == '':`
                * `pass` (simplemente continÃºa)
            * `else`:
                * `print("[Sistema: Feedback no reconocido, continuando...]")`
        * **IMPORTANTE:** Este bloque de feedback debe estar *dentro* del `while True` principal, pero *fuera* del bloque `try...except`.

---

**Instrucciones de EjecuciÃ³n (Para el Usuario Final):**

* El usuario debe ejecutar la aplicaciÃ³n con `python console_agent.py`.

**Resultado Esperado:**
La aplicaciÃ³n de consola `console_agent.py` ahora funciona como un ciclo completo de auto-mejora:
1.  El usuario (ej. "user_123") inicia el chat.
2.  El bot usa el prompt V1 (base) porque la BD estÃ¡ vacÃ­a.
3.  El usuario pregunta: "Â¿QuÃ© garantÃ­as tienen?"
4.  El bot da una respuesta vaga: "Tenemos garantÃ­as en nuestros autos."
5.  El sistema pregunta: `Â¿Esta respuesta fue Ãºtil? ( ğŸ‘ / ğŸ‘ / 'siguiente' para continuar )`
6.  El usuario escribe: `ğŸ‘`
7.  El "Agente Optimizador" se activa, llama a OpenAI y genera una regla.
8.  La consola imprime: `[Sistema: ğŸ‘ Nueva regla aprendida y guardada.]`.
9.  El usuario pregunta: "Â¿QuÃ© Jettas tienes?"
10. El bot responde: "Tenemos varios Jettas. Â¿Te interesa algÃºn aÃ±o o color?"
11. El sistema pregunta por feedback.
12. El usuario escribe: `ğŸ‘`
13. El "Agente Resumidor" se activa y genera un resumen (ej. "Usuario estÃ¡ buscando Jettas.").
14. La consola imprime: `[Sistema: ğŸ‘ Memoria guardada exitosamente.]`.
15. **PRUEBA FINAL:** El usuario cierra el programa (`salir`) y lo **vuelve a ejecutar** con el mismo `user_id` ("user_123").
16. Al iniciar, `build_system_prompt` ahora carga la regla y la memoria.
17. El usuario pregunta: "Â¿QuÃ© garantÃ­as tienen?"
18. El bot (ahora "Run 2") da la respuesta mejorada: "Â¡Claro! Tenemos una garantÃ­a mecÃ¡nica de 3 meses..."
import os
import sqlite3
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage, AIMessage
import httpx


# Configuraci√≥n inicial
load_dotenv()

# Limpiar variables de proxy del entorno para evitar conflictos
os.environ.pop('HTTP_PROXY', None)
os.environ.pop('HTTPS_PROXY', None)
os.environ.pop('http_proxy', None)
os.environ.pop('https_proxy', None)


# Funciones de Base de Datos (Lectura)
def get_db_connection():
    """Helper para obtener conexi√≥n a la base de datos"""
    return sqlite3.connect('kavak_memory.db')


def get_all_rules():
    """
    Obtiene todas las reglas de la tabla prompt_rules.
    Retorna un string con todas las reglas unidas por saltos de l√≠nea.
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute('SELECT rule_text FROM prompt_rules')
    results = cursor.fetchall()
    
    conn.close()
    
    if results:
        # Unir todas las reglas con saltos de l√≠nea
        return '\n'.join([row[0] for row in results])
    return ''


def get_user_memory(user_id):
    """
    Obtiene TODA la memoria hist√≥rica del usuario (todas las conversaciones previas).
    Retorna un string formateado con todos los contextos acumulados.
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute(
        'SELECT context FROM user_memory WHERE user_id = ? ORDER BY id ASC',
        (user_id,)
    )
    results = cursor.fetchall()
    
    conn.close()
    
    if results:
        # Combinar todas las memorias en un solo contexto
        all_memories = '\n'.join([f"- {row[0]}" for row in results])
        return f"HISTORIAL DE MEMORIA DEL USUARIO:\n{all_memories}"
    return ''


def save_user_memory(user_id, chat_history_list, llm_instance):
    """
    Agente Resumidor: Genera y guarda un resumen de la conversaci√≥n en user_memory.
    Usa la instancia llm_instance ya configurada para evitar errores de proxy.
    """
    MEMORY_PROMPT = "Eres un agente resumidor. Basado en esta conversaci√≥n, extrae el inter√©s clave, problema o intenci√≥n del usuario en una sola frase concisa para usarla como memoria a futuro."
    
    # Crear lista de mensajes para el resumidor
    messages_for_summary = [SystemMessage(content=MEMORY_PROMPT)] + chat_history_list
    
    # Llamar al LLM usando la instancia configurada
    response = llm_instance.invoke(messages_for_summary)
    summary_text = response.content
    
    # Guardar en la base de datos
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute(
        'INSERT INTO user_memory (user_id, context) VALUES (?, ?)',
        (user_id, summary_text)
    )
    
    conn.commit()
    conn.close()
    
    print("\n[Sistema: ‚úì Memoria guardada exitosamente. Esta informaci√≥n se recordar√° en futuras conversaciones.]")


def optimize_prompt_rule(chat_history_list, llm_instance):
    """
    Agente Optimizador: Genera y guarda una nueva regla de prompt en prompt_rules.
    Usa la instancia llm_instance ya configurada para evitar errores de proxy.
    """
    # Extraer la √∫ltima pregunta y respuesta
    last_human_message = None
    last_ai_message = None
    
    # Buscar desde el final hacia atr√°s
    for msg in reversed(chat_history_list):
        if isinstance(msg, AIMessage) and last_ai_message is None:
            last_ai_message = msg.content
        elif isinstance(msg, HumanMessage) and last_human_message is None:
            last_human_message = msg.content
        
        if last_human_message and last_ai_message:
            break
    
    if not last_human_message or not last_ai_message:
        print("\n[Sistema: ‚ö†Ô∏è  No se pudo extraer la conversaci√≥n para optimizar.]")
        return
    
    # Definir el prompt del optimizador
    OPTIMIZER_PROMPT = f"""Eres un 'Optimizador de Prompts' experto. La siguiente respuesta del bot a la pregunta del usuario fue marcada como 'No √ötil'.

Tu tarea es analizar el fallo y generar una 'REGLA:' corta y espec√≠fica para el prompt del sistema que ayude a bots futuros a evitar este error.
La regla debe ser accionable y clara.

Ejemplo de Regla: 'REGLA: Si el usuario pregunta por garant√≠a, siempre mencionar la garant√≠a mec√°nica de 3 meses.'

---
Pregunta del Usuario que fall√≥: {last_human_message}
Respuesta del Bot que fall√≥: {last_ai_message}
---

Genera la nueva REGLA:"""
    
    # Llamar al LLM usando la instancia configurada
    response = llm_instance.invoke([HumanMessage(content=OPTIMIZER_PROMPT)])
    new_rule_text = response.content
    
    # Guardar en la base de datos
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute(
        'INSERT INTO prompt_rules (rule_text) VALUES (?)',
        (new_rule_text,)
    )
    
    conn.commit()
    conn.close()
    
    print("\n[Sistema: ‚úì Nueva regla aprendida y guardada. El bot mejorar√° sus respuestas.]")


def calculate_metrics(chat_history):
    """
    Calcula m√©tricas de la conversaci√≥n para mostrar al final.
    Retorna un diccionario con las m√©tricas calculadas.
    """
    # Extraer solo mensajes de usuario y bot (sin SystemMessage)
    user_messages = []
    bot_messages = []
    
    for msg in chat_history:
        if isinstance(msg, HumanMessage):
            user_messages.append(msg.content)
        elif isinstance(msg, AIMessage):
            bot_messages.append(msg.content)
    
    # M√âTRICA 1: Tasa de Resoluci√≥n (basada en especificidad de respuestas)
    keywords_especificos = [
        '3 meses', '3,000 km', '7 d√≠as', '$', 'MXN', 'pesos',
        '12.9%', '24.9%', '10%', 'enganche', 'tasa',
        'Versa', 'Jetta', 'Corolla', 'Civic', 'Mazda',
        '240 puntos', 'inspecci√≥n', 'Hub', 'Kavak',
        '800-KAVAK', 'SPEI', '24-48 horas', '5 minutos',
        'garant√≠a', 'financiamiento', 'precio'
    ]
    
    resolved_count = 0
    for response in bot_messages:
        keyword_count = sum(1 for keyword in keywords_especificos if keyword.lower() in response.lower())
        if keyword_count >= 2:
            resolved_count += 1
    
    resolution_rate = (resolved_count / len(bot_messages) * 100) if bot_messages else 0
    
    # M√âTRICA 2: Precisi√≥n y Completitud (longitud promedio y densidad de informaci√≥n)
    avg_response_length = sum(len(msg) for msg in bot_messages) / len(bot_messages) if bot_messages else 0
    
    total_keywords = 0
    for response in bot_messages:
        total_keywords += sum(1 for keyword in keywords_especificos if keyword.lower() in response.lower())
    
    keyword_density = (total_keywords / len(bot_messages)) if bot_messages else 0
    
    # Clasificar completitud
    if keyword_density >= 5:
        completitud = "EXCELENTE"
    elif keyword_density >= 3:
        completitud = "BUENA"
    elif keyword_density >= 1:
        completitud = "REGULAR"
    else:
        completitud = "BAJA"
    
    return {
        'total_interactions': len(user_messages),
        'resolved_count': resolved_count,
        'resolution_rate': resolution_rate,
        'avg_response_length': avg_response_length,
        'keyword_density': keyword_density,
        'completitud': completitud,
        'user_messages': user_messages,
        'bot_messages': bot_messages
    }


def display_metrics(metrics):
    """
    Muestra las m√©tricas de forma visual al final de la conversaci√≥n.
    """
    print("\n" + "="*70)
    print("üìä REPORTE DE M√âTRICAS DE LA CONVERSACI√ìN")
    print("="*70)
    
    # M√âTRICA 1: COMPARACI√ìN PAREADA (La Tabla)
    print("\n1Ô∏è‚É£  COMPARACI√ìN PAREADA - Historial de Interacciones")
    print("‚îÄ"*70)
    
    for i in range(metrics['total_interactions']):
        print(f"\n[Interacci√≥n {i+1}]")
        print(f"üë§ Usuario: {metrics['user_messages'][i][:100]}{'...' if len(metrics['user_messages'][i]) > 100 else ''}")
        print(f"ü§ñ Kavak:   {metrics['bot_messages'][i][:100]}{'...' if len(metrics['bot_messages'][i]) > 100 else ''}")
    
    # M√âTRICA 2: TASA DE RESOLUCI√ìN (El Puntaje)
    print("\n" + "‚îÄ"*70)
    print("2Ô∏è‚É£  TASA DE RESOLUCI√ìN DE PROBLEMAS")
    print("‚îÄ"*70)
    print(f"\n   Respuestas con datos espec√≠ficos: {metrics['resolved_count']}/{metrics['total_interactions']}")
    print(f"   Tasa de Resoluci√≥n: {metrics['resolution_rate']:.1f}%")
    
    # Barra visual
    bar_length = 30
    filled = int((metrics['resolution_rate'] / 100) * bar_length)
    bar = "‚ñà" * filled + "‚ñë" * (bar_length - filled)
    print(f"   [{bar}] {metrics['resolution_rate']:.1f}%")
    
    if metrics['resolution_rate'] >= 80:
        print("   ‚úÖ EXCELENTE - El bot proporcion√≥ informaci√≥n espec√≠fica")
    elif metrics['resolution_rate'] >= 60:
        print("   ‚úì BUENO - La mayor√≠a de respuestas fueron espec√≠ficas")
    elif metrics['resolution_rate'] >= 40:
        print("   ‚ö†Ô∏è  REGULAR - Algunas respuestas fueron vagas")
    else:
        print("   ‚ùå BAJO - El bot necesita m√°s datos espec√≠ficos")
    
    # M√âTRICA 3: PRECISI√ìN Y COMPLETITUD (La Explicaci√≥n)
    print("\n" + "‚îÄ"*70)
    print("3Ô∏è‚É£  PRECISI√ìN Y COMPLETITUD")
    print("‚îÄ"*70)
    print(f"\n   Longitud promedio de respuestas: {metrics['avg_response_length']:.0f} caracteres")
    print(f"   Densidad de informaci√≥n: {metrics['keyword_density']:.1f} datos espec√≠ficos por respuesta")
    print(f"   Nivel de Completitud: {metrics['completitud']}")
    
    if metrics['completitud'] == "EXCELENTE":
        print("   ‚úÖ Las respuestas incluyen m√∫ltiples datos concretos (precios, plazos, etc.)")
    elif metrics['completitud'] == "BUENA":
        print("   ‚úì Las respuestas incluyen datos espec√≠ficos relevantes")
    elif metrics['completitud'] == "REGULAR":
        print("   ‚ö†Ô∏è  Las respuestas podr√≠an ser m√°s espec√≠ficas")
    else:
        print("   ‚ùå Las respuestas carecen de datos concretos")
    
    print("\n" + "="*70)
    print("Fin del Reporte de M√©tricas")
    print("="*70 + "\n")


def build_system_prompt(user_id):
    """
    Construye el prompt del sistema combinando:
    - PROMPT_BASE (instrucciones base)
    - Reglas de la BD
    - Memoria del usuario
    """
    PROMPT_BASE = """Eres un asistente virtual experto de Kavak, la plataforma l√≠der de compra y venta de autos seminuevos en Latinoam√©rica.

SIEMPRE proporciona informaci√≥n ESPEC√çFICA, DETALLADA y con DATOS CONCRETOS. Nunca des respuestas vagas o gen√©ricas.

INFORMACI√ìN CORPORATIVA:
- Fundada en 2016 en M√©xico
- Presencia en 7 pa√≠ses: M√©xico, Argentina, Chile, Brasil, Colombia, Per√∫ y Turqu√≠a
- M√°s de 20 centros de distribuci√≥n (Hubs)
- Inventario de +10,000 autos disponibles
- +300,000 autos vendidos desde fundaci√≥n

1. COMPRA DE AUTOS - DATOS ESPEC√çFICOS:

INVENTARIO:
- Marcas: Nissan, VW, Chevrolet, Toyota, Honda, Mazda, Ford, Hyundai, KIA, Seat
- Modelos populares: Versa, Jetta, Aveo, Vento, Sentra, March, Corolla, Civic, Mazda 3
- Precios: $120,000 - $800,000 MXN
- A√±os: 2015-2022 t√≠picamente
- Kilometraje: 30,000 - 120,000 km

PROCESO (7 PASOS):
1. B√∫squeda online con filtros
2. Agenda prueba de manejo (sin compromiso)
3. Revisi√≥n del auto (inspecci√≥n 240 puntos)
4. Simulaci√≥n de cr√©dito (respuesta en 5 min)
5. Apartado con $5,000 MXN (reembolsable en 7 d√≠as)
6. Firma de contrato (digital o presencial)
7. Entrega mismo d√≠a o a domicilio (gratis)

BENEFICIOS:
- Garant√≠a mec√°nica: 3 meses o 3,000 km
- Garant√≠a de satisfacci√≥n: 7 d√≠as devoluci√≥n sin preguntas
- Entrega a domicilio sin costo
- Tr√°mites incluidos: placas, tenencia, verificaci√≥n
- Seguro incluido primer mes (cobertura amplia)

2. VENTA DE AUTOS - PROCESO DETALLADO:

PASOS (6 ETAPAS):
1. Cotizaci√≥n online (2 minutos): marca, modelo, a√±o, km
2. Valuaci√≥n inicial: rango de precio inmediato
3. Inspecci√≥n f√≠sica en Hub (30-45 min)
4. Oferta final al terminar inspecci√≥n
5. Pago en 24-48 horas si aceptas
6. Kavak hace todos los tr√°mites

CRITERIOS:
- A√±os: 2010 en adelante generalmente
- Kilometraje m√°ximo: 200,000 km
- Documentos: factura, tarjeta circulaci√≥n, verificaciones
- NO aceptamos: adeudos, robados, da√±os estructurales graves

PAGO:
- Transferencia SPEI: 24-48 hrs
- Cheque certificado: mismo d√≠a
- Efectivo: solo hasta $100,000 MXN

3. FINANCIAMIENTO - INFORMACI√ìN PRECISA:

OPCIONES:
- Enganche desde: 10% del valor
- Plazos: 12, 24, 36, 48, 60 meses
- Tasa anual: 12.9% - 24.9% (seg√∫n perfil)
- Monto m√°ximo: $600,000 MXN
- Comisi√≥n apertura: 3% del monto

REQUISITOS:
- Edad: 18-70 a√±os
- Ingresos m√≠nimos: $8,000 MXN/mes comprobables
- Antig√ºedad laboral: 6 meses m√≠nimo
- Score bur√≥: m√≠nimo 550
- Docs: INE, comprobante domicilio, 3 √∫ltimos recibos

APROBACI√ìN:
- Pre-aprobaci√≥n: 5 minutos online
- An√°lisis: 24-48 horas
- Alianzas: Santander, BBVA, Scotiabank, Cr√©dito Kavak

4. GARANT√çA MEC√ÅNICA (3 MESES/3,000 KM):

CUBRE:
- Motor: bloque, cig√ºe√±al, pistones, bielas, v√°lvulas
- Transmisi√≥n: caja completa (manual/autom√°tica)
- Sistema el√©ctrico: alternador, marcha, computadora
- Direcci√≥n: caja, bomba hidr√°ulica
- Suspensi√≥n: amortiguadores, brazos
- Frenos: bomba, booster

NO CUBRE:
- Desgaste normal: balatas, llantas, filtros
- Da√±os por mal uso o accidentes
- Mantenimiento preventivo

C√ìMO USAR GARANT√çA:
1. Llama al 800-KAVAK-01
2. Describe el problema
3. Agenda cita en taller autorizado
4. Kavak cubre reparaci√≥n si aplica

5. INSPECCI√ìN 240 PUNTOS:

CATEGOR√çAS:
- Motor (40 puntos): compresi√≥n, fugas, ruidos
- Transmisi√≥n (25 puntos): cambios, sincronizaci√≥n
- Frenos (20 puntos): discos, balatas, l√≠quido
- Suspensi√≥n (25 puntos): amortiguadores, r√≥tulas
- El√©ctrico (30 puntos): bater√≠a, luces, sensores
- Carrocer√≠a (40 puntos): pintura, abolladuras, √≥xido
- Interior (30 puntos): asientos, tablero, clima
- Documentaci√≥n (30 puntos): factura, adeudos, historial

PROCESO:
- Duraci√≥n: 2-3 horas por auto
- Mec√°nicos certificados
- Reporte digital disponible para cada auto
- Solo pasan autos en buen estado (70% rechazados)

INSTRUCCIONES CR√çTICAS:
- SIEMPRE menciona n√∫meros, plazos, montos espec√≠ficos
- NUNCA digas solo "tenemos garant√≠as" - especifica 3 meses/3,000 km
- NUNCA digas "varios modelos" - menciona marcas y modelos concretos
- Si preguntan por precio, da rangos reales ($120k-$800k MXN)
- Si preguntan por financiamiento, menciona tasas (12.9%-24.9%)
- S√© amigable pero SIEMPRE con datos concretos
- Si no sabes algo MUY espec√≠fico, ofrece conectar con asesor"""

    # Obtener reglas y memoria
    rules = get_all_rules()
    memory = get_user_memory(user_id)
    
    # Combinar todo en el prompt final
    final_prompt = PROMPT_BASE
    
    if rules:
        final_prompt += f"\n\nREGLAS ADICIONALES:\n{rules}"
    
    if memory:
        final_prompt += f"\n\n{memory}"
    
    return final_prompt


def main():
    """
    Bucle principal del chatbot en consola.
    """
    print("=" * 60)
    print("üöó BIENVENIDO AL ASISTENTE VIRTUAL DE KAVAK üöó")
    print("=" * 60)
    print("\nEscribe 'salir' en cualquier momento para terminar la conversaci√≥n.\n")
    
    # Solicitar user_id (simulaci√≥n de login)
    user_id = input("Por favor, ingresa tu ID de usuario: ").strip()
    
    if not user_id:
        print("‚ùå Error: Debes ingresar un ID de usuario v√°lido.")
        return
    
    print(f"\n‚úÖ Sesi√≥n iniciada para usuario: {user_id}")
    print("\nCargando asistente...")
    
    # Configurar clientes HTTP (s√≠ncrono y as√≠ncrono) con timeout personalizado
    sync_client = httpx.Client(timeout=30.0)
    async_client = httpx.AsyncClient(timeout=30.0)
    
    # Inicializar el LLM con clientes HTTP personalizados
    llm = ChatOpenAI(
        model="gpt-3.5-turbo", 
        temperature=0.7,
        http_client=sync_client,
        http_async_client=async_client
    )
    
    # Construir el prompt del sistema
    system_prompt = build_system_prompt(user_id)
    
    # Inicializar historial de chat
    chat_history = [SystemMessage(content=system_prompt)]
    
    print("\n" + "=" * 60)
    print("Puedes empezar a chatear con el asistente de Kavak")
    print("=" * 60)
    
    # Bucle principal de conversaci√≥n
    while True:
        # Obtener input del usuario
        user_input = input("\nüßë T√∫: ").strip()
        
        # Verificar comando de salida
        if user_input.lower() == 'salir':
            # Calcular y mostrar m√©tricas antes de salir
            if len(chat_history) > 1:  # Si hubo al menos una interacci√≥n
                print("\n" + "="*70)
                print("Generando reporte de m√©tricas de tu conversaci√≥n...")
                print("="*70)
                
                metrics = calculate_metrics(chat_history)
                display_metrics(metrics)
            
            print("\nüëã ¬°Gracias por usar el asistente de Kavak! Hasta pronto.")
            break
        
        # Validar que el input no est√© vac√≠o
        if not user_input:
            print("‚ö†Ô∏è  Por favor, escribe algo.")
            continue
        
        # A√±adir mensaje del usuario al historial
        chat_history.append(HumanMessage(content=user_input))
        
        # Mostrar mensaje de espera
        print("\nü§ñ Kavak pensando...")
        
        try:
            # Llamar a la IA
            response = llm.invoke(chat_history)
            ai_response_content = response.content
            
            # Mostrar respuesta
            print(f"\nüöó Kavak: {ai_response_content}")
            
            # A√±adir respuesta del bot al historial para mantener contexto
            chat_history.append(AIMessage(content=ai_response_content))
            
            # Sistema de feedback
            print("\n¬øEsta respuesta fue √∫til? (si / no / Enter para continuar)")
            feedback = input("Tu feedback: ").strip().lower()
            
            if feedback == 'si' or feedback == 's':
                save_user_memory(user_id, chat_history, llm)
            elif feedback == 'no' or feedback == 'n':
                optimize_prompt_rule(chat_history, llm)
                # Reconstruir el prompt con la nueva regla para mejorar en esta misma conversaci√≥n
                print("\n[Sistema: Aplicando mejora al asistente...]")
                system_prompt = build_system_prompt(user_id)
                # Actualizar el system message en el historial
                chat_history[0] = SystemMessage(content=system_prompt)
                print("[Sistema: ‚úì Asistente mejorado. Continuemos...]")
            elif feedback == '' or feedback == 'siguiente':
                pass  # Continuar sin hacer nada
            else:
                print("[Sistema: Feedback no reconocido, continuando...]")
            
        except Exception as e:
            print(f"\n‚ùå Error al comunicarse con la IA: {str(e)}")
            print("Por favor, verifica tu configuraci√≥n de API key en el archivo .env")
            break


if __name__ == "__main__":
    main()

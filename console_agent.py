import os
import sqlite3
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage, AIMessage
import httpx


# Configuraci√≥n inicial
load_dotenv()

# Limpiar variables de proxy del entorno para evitar conflictos
os.environ.pop('HTTP_PROXY', None)
os.environ.pop('HTTPS_PROXY', None)
os.environ.pop('http_proxy', None)
os.environ.pop('https_proxy', None)


# Funciones de Base de Datos (Lectura)
def get_db_connection():
    """Helper para obtener conexi√≥n a la base de datos"""
    return sqlite3.connect('kavak_memory.db')


def get_all_rules():
    """
    Obtiene todas las reglas de la tabla prompt_rules.
    Retorna un string con todas las reglas unidas por saltos de l√≠nea.
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute('SELECT rule_text FROM prompt_rules')
    results = cursor.fetchall()
    
    conn.close()
    
    if results:
        # Unir todas las reglas con saltos de l√≠nea
        return '\n'.join([row[0] for row in results])
    return ''


def get_user_memory(user_id):
    """
    Obtiene TODA la memoria hist√≥rica del usuario (todas las conversaciones previas).
    Retorna un string formateado con todos los contextos acumulados.
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute(
        'SELECT context FROM user_memory WHERE user_id = ? ORDER BY id ASC',
        (user_id,)
    )
    results = cursor.fetchall()
    
    conn.close()
    
    if results:
        # Combinar todas las memorias en un solo contexto
        all_memories = '\n'.join([f"- {row[0]}" for row in results])
        return f"HISTORIAL DE MEMORIA DEL USUARIO:\n{all_memories}"
    return ''


def save_user_memory(user_id, chat_history_list, llm_instance):
    """
    Agente Resumidor: Genera y guarda un resumen de la conversaci√≥n en user_memory.
    Usa la instancia llm_instance ya configurada para evitar errores de proxy.
    """
    MEMORY_PROMPT = "Eres un agente resumidor. Basado en esta conversaci√≥n, extrae el inter√©s clave, problema o intenci√≥n del usuario en una sola frase concisa para usarla como memoria a futuro."
    
    # Crear lista de mensajes para el resumidor
    messages_for_summary = [SystemMessage(content=MEMORY_PROMPT)] + chat_history_list
    
    # Llamar al LLM usando la instancia configurada
    response = llm_instance.invoke(messages_for_summary)
    summary_text = response.content
    
    # Guardar en la base de datos
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute(
        'INSERT INTO user_memory (user_id, context) VALUES (?, ?)',
        (user_id, summary_text)
    )
    
    conn.commit()
    conn.close()
    
    print("\n[Sistema: ‚úì Memoria guardada exitosamente. Esta informaci√≥n se recordar√° en futuras conversaciones.]")


def categorize_error(question, answer, llm_instance):
    """
    Categoriza el tipo de error en la respuesta.
    Retorna: categoria y descripci√≥n.
    """
    categorization_prompt = f"""Analiza esta interacci√≥n fallida y categoriza el tipo de error.

PREGUNTA: {question}
RESPUESTA: {answer}

CATEGOR√çAS POSIBLES:
- vago: Respuesta gen√©rica sin datos espec√≠ficos
- incorrecto: Informaci√≥n err√≥nea o desactualizada
- incompleto: Falta informaci√≥n importante
- fuera_contexto: No aborda la pregunta del usuario
- general: Otro tipo de error

Responde SOLO con el nombre de la categor√≠a (una palabra)."""

    try:
        response = llm_instance.invoke([HumanMessage(content=categorization_prompt)])
        category = response.content.strip().lower()
        
        # Validar categor√≠a
        valid_categories = ['vago', 'incorrecto', 'incompleto', 'fuera_contexto', 'general']
        if category not in valid_categories:
            category = 'general'
        
        return category
    except:
        return 'general'


def validate_rule(rule_text, test_question, llm_instance):
    """
    Valida si una regla nueva realmente mejora las respuestas.
    Retorna score de validaci√≥n (0.0 - 1.0).
    """
    # Crear prompt con y sin la regla
    base_prompt = "Eres un asistente de Kavak. Responde de forma √∫til."
    improved_prompt = f"{base_prompt}\n\n{rule_text}"
    
    # Probar sin regla
    response_without = llm_instance.invoke([
        SystemMessage(content=base_prompt),
        HumanMessage(content=test_question)
    ])
    
    # Probar con regla
    response_with = llm_instance.invoke([
        SystemMessage(content=improved_prompt),
        HumanMessage(content=test_question)
    ])
    
    # Evaluar ambas respuestas
    judge_prompt = f"""Compara estas dos respuestas a la pregunta: "{test_question}"

RESPUESTA A (sin regla): {response_without.content[:200]}
RESPUESTA B (con regla): {response_with.content[:200]}

¬øLa Respuesta B es mejor que la Respuesta A?
Responde SOLO: "si" o "no"."""
    
    try:
        judgment = llm_instance.invoke([HumanMessage(content=judge_prompt)])
        is_better = judgment.content.strip().lower()
        
        return 1.0 if 'si' in is_better or 's√≠' in is_better else 0.0
    except:
        return 0.5  # Score neutral si falla


def optimize_prompt_rule(chat_history_list, llm_instance):
    """
    Agente Optimizador MEJORADO: Categoriza errores y valida reglas antes de guardar.
    """
    # Extraer la √∫ltima pregunta y respuesta
    last_human_message = None
    last_ai_message = None
    
    for msg in reversed(chat_history_list):
        if isinstance(msg, AIMessage) and last_ai_message is None:
            last_ai_message = msg.content
        elif isinstance(msg, HumanMessage) and last_human_message is None:
            last_human_message = msg.content
        
        if last_human_message and last_ai_message:
            break
    
    if not last_human_message or not last_ai_message:
        print("\n[Sistema: ‚ö†Ô∏è  No se pudo extraer la conversaci√≥n para optimizar.]")
        return
    
    # PASO 1: Categorizar el error
    print("\n[Sistema: Analizando tipo de error...]")
    error_category = categorize_error(last_human_message, last_ai_message, llm_instance)
    print(f"[Sistema: Error categorizado como '{error_category}']")
    
    # PASO 2: Generar regla
    OPTIMIZER_PROMPT = f"""Eres un 'Optimizador de Prompts' experto. La siguiente respuesta del bot fue marcada como 'No √ötil' (tipo de error: {error_category}).

Tu tarea es generar una 'REGLA:' corta y espec√≠fica para mejorar futuras respuestas.

Ejemplo: 'REGLA: Si el usuario pregunta por garant√≠a, siempre mencionar la garant√≠a mec√°nica de 3 meses.'

---
Pregunta del Usuario: {last_human_message}
Respuesta del Bot (fallida): {last_ai_message}
Tipo de error: {error_category}
---

Genera la nueva REGLA:"""
    
    response = llm_instance.invoke([HumanMessage(content=OPTIMIZER_PROMPT)])
    new_rule_text = response.content
    
    # PASO 3: Validar la regla
    print("[Sistema: Validando efectividad de la regla...]")
    validation_score = validate_rule(new_rule_text, last_human_message, llm_instance)
    
    # PASO 4: Guardar solo si la validaci√≥n es positiva
    if validation_score >= 0.5:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute(
            'INSERT INTO prompt_rules (rule_text, error_category, validation_score) VALUES (?, ?, ?)',
            (new_rule_text, error_category, validation_score)
        )
        
        conn.commit()
        conn.close()
        
        print(f"\n[Sistema: ‚úì Regla validada (score: {validation_score:.1f}) y guardada. Categor√≠a: {error_category}]")
    else:
        print(f"\n[Sistema: ‚úó Regla descartada (score: {validation_score:.1f}). No mejora las respuestas.]")


def calculate_metrics(chat_history):
    """
    Calcula m√©tricas de la conversaci√≥n para mostrar al final.
    Retorna un diccionario con las m√©tricas calculadas.
    """
    # Extraer solo mensajes de usuario y bot (sin SystemMessage)
    user_messages = []
    bot_messages = []
    
    for msg in chat_history:
        if isinstance(msg, HumanMessage):
            user_messages.append(msg.content)
        elif isinstance(msg, AIMessage):
            bot_messages.append(msg.content)
    
    # M√âTRICA 1: Tasa de Resoluci√≥n (basada en especificidad de respuestas)
    keywords_especificos = [
        '3 meses', '3,000 km', '7 d√≠as', '$', 'MXN', 'pesos',
        '12.9%', '24.9%', '10%', 'enganche', 'tasa',
        'Versa', 'Jetta', 'Corolla', 'Civic', 'Mazda',
        '240 puntos', 'inspecci√≥n', 'Hub', 'Kavak',
        '800-KAVAK', 'SPEI', '24-48 horas', '5 minutos',
        'garant√≠a', 'financiamiento', 'precio'
    ]
    
    resolved_count = 0
    for response in bot_messages:
        keyword_count = sum(1 for keyword in keywords_especificos if keyword.lower() in response.lower())
        if keyword_count >= 2:
            resolved_count += 1
    
    resolution_rate = (resolved_count / len(bot_messages) * 100) if bot_messages else 0
    
    # M√âTRICA 2: Precisi√≥n y Completitud (longitud promedio y densidad de informaci√≥n)
    avg_response_length = sum(len(msg) for msg in bot_messages) / len(bot_messages) if bot_messages else 0
    
    total_keywords = 0
    for response in bot_messages:
        total_keywords += sum(1 for keyword in keywords_especificos if keyword.lower() in response.lower())
    
    keyword_density = (total_keywords / len(bot_messages)) if bot_messages else 0
    
    # Clasificar completitud
    if keyword_density >= 5:
        completitud = "EXCELENTE"
    elif keyword_density >= 3:
        completitud = "BUENA"
    elif keyword_density >= 1:
        completitud = "REGULAR"
    else:
        completitud = "BAJA"
    
    return {
        'total_interactions': len(user_messages),
        'resolved_count': resolved_count,
        'resolution_rate': resolution_rate,
        'avg_response_length': avg_response_length,
        'keyword_density': keyword_density,
        'completitud': completitud,
        'user_messages': user_messages,
        'bot_messages': bot_messages
    }


def auto_learn_from_conversation(chat_history, user_id, llm_instance):
    """
    Analiza autom√°ticamente la conversaci√≥n y aprende patrones exitosos.
    Se ejecuta al finalizar cada conversaci√≥n SIN intervenci√≥n del usuario.
    """
    # Extraer mensajes de usuario y bot
    interactions = []
    for i in range(len(chat_history)):
        if isinstance(chat_history[i], HumanMessage):
            if i + 1 < len(chat_history) and isinstance(chat_history[i+1], AIMessage):
                interactions.append({
                    'question': chat_history[i].content,
                    'answer': chat_history[i+1].content
                })
    
    if not interactions:
        return
    
    # Analizar qu√© respuestas fueron espec√≠ficas (aprendizaje autom√°tico)
    keywords_especificos = [
        '3 meses', '3,000 km', '7 d√≠as', '$', 'MXN', 'pesos',
        '12.9%', '24.9%', '10%', 'enganche', 'tasa',
        'Versa', 'Jetta', 'Corolla', 'Civic', 'Mazda',
        '240 puntos', 'inspecci√≥n', 'Hub', 'Kavak',
        '800-KAVAK', 'SPEI', '24-48 horas', '5 minutos'
    ]
    
    conn = get_db_connection()
    cursor = conn.cursor()
    
    learned_something = False
    
    for interaction in interactions:
        keyword_count = sum(1 for kw in keywords_especificos if kw.lower() in interaction['answer'].lower())
        
        # Si la respuesta fue espec√≠fica (>=3 keywords), aprender de ella
        if keyword_count >= 3:
            # Generar regla autom√°ticamente usando el LLM
            learning_prompt = f"""Analiza esta interacci√≥n exitosa y genera UNA regla corta y espec√≠fica para mejorar futuras respuestas similares.

Pregunta del usuario: {interaction['question']}
Respuesta exitosa del bot: {interaction['answer'][:200]}...

Genera solo la REGLA en formato: 'REGLA: [regla espec√≠fica]'
Ejemplo: 'REGLA: Si preguntan por garant√≠as, siempre mencionar 3 meses/3,000 km y 7 d√≠as de satisfacci√≥n.'"""
            
            try:
                response = llm_instance.invoke([HumanMessage(content=learning_prompt)])
                new_rule = response.content.strip()
                
                # Verificar que no sea una regla duplicada
                cursor.execute('SELECT COUNT(*) FROM prompt_rules WHERE rule_text = ?', (new_rule,))
                if cursor.fetchone()[0] == 0:
                    cursor.execute('INSERT INTO prompt_rules (rule_text) VALUES (?)', (new_rule,))
                    learned_something = True
            except:
                pass  # Si falla, continuar sin romper el flujo
    
    # Guardar memoria del usuario autom√°ticamente
    if interactions:
        memory_prompt = f"Resume en UNA frase el inter√©s principal del usuario basado en estas preguntas: {', '.join([i['question'] for i in interactions[:3]])}"
        try:
            response = llm_instance.invoke([HumanMessage(content=memory_prompt)])
            summary = response.content.strip()
            cursor.execute('INSERT INTO user_memory (user_id, context) VALUES (?, ?)', (user_id, summary))
        except:
            pass
    
    conn.commit()
    conn.close()
    
    if learned_something:
        print("\n[Sistema: El bot aprendi√≥ autom√°ticamente de esta conversaci√≥n]")


def get_system_evolution_metrics():
    """
    Calcula m√©tricas de evoluci√≥n del sistema a lo largo del tiempo.
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    
    # Contar reglas aprendidas
    cursor.execute('SELECT COUNT(*) FROM prompt_rules')
    total_rules = cursor.fetchone()[0]
    
    # Contar memorias de usuarios
    cursor.execute('SELECT COUNT(DISTINCT user_id) FROM user_memory')
    total_users = cursor.fetchone()[0]
    
    cursor.execute('SELECT COUNT(*) FROM user_memory')
    total_memories = cursor.fetchone()[0]
    
    # An√°lisis de errores por categor√≠a
    cursor.execute('''
        SELECT error_category, COUNT(*) as count 
        FROM prompt_rules 
        WHERE error_category IS NOT NULL
        GROUP BY error_category
    ''')
    error_distribution = dict(cursor.fetchall())
    
    # Score promedio de validaci√≥n
    cursor.execute('SELECT AVG(validation_score) FROM prompt_rules WHERE validation_score > 0')
    avg_validation = cursor.fetchone()[0] or 0.0
    
    conn.close()
    
    return {
        'total_rules': total_rules,
        'total_users': total_users,
        'total_memories': total_memories,
        'error_distribution': error_distribution,
        'avg_validation_score': avg_validation
    }


def display_metrics(metrics):
    """
    Muestra las m√©tricas de forma visual al final de la conversaci√≥n.
    """
    print("\n" + "="*70)
    print("üìä REPORTE DE M√âTRICAS DE LA CONVERSACI√ìN")
    print("="*70)
    
    # M√âTRICA 1: COMPARACI√ìN PAREADA (La Tabla)
    print("\n1Ô∏è‚É£  COMPARACI√ìN PAREADA - Historial de Interacciones")
    print("‚îÄ"*70)
    
    for i in range(metrics['total_interactions']):
        print(f"\n[Interacci√≥n {i+1}]")
        print(f"üë§ Usuario: {metrics['user_messages'][i][:100]}{'...' if len(metrics['user_messages'][i]) > 100 else ''}")
        print(f"ü§ñ Kavak:   {metrics['bot_messages'][i][:100]}{'...' if len(metrics['bot_messages'][i]) > 100 else ''}")
    
    # M√âTRICA 2: TASA DE RESOLUCI√ìN (El Puntaje)
    print("\n" + "‚îÄ"*70)
    print("2Ô∏è‚É£  TASA DE RESOLUCI√ìN DE PROBLEMAS")
    print("‚îÄ"*70)
    print(f"\n   Respuestas con datos espec√≠ficos: {metrics['resolved_count']}/{metrics['total_interactions']}")
    print(f"   Tasa de Resoluci√≥n: {metrics['resolution_rate']:.1f}%")
    
    # Barra visual
    bar_length = 30
    filled = int((metrics['resolution_rate'] / 100) * bar_length)
    bar = "‚ñà" * filled + "‚ñë" * (bar_length - filled)
    print(f"   [{bar}] {metrics['resolution_rate']:.1f}%")
    
    if metrics['resolution_rate'] >= 80:
        print("   ‚úÖ EXCELENTE - El bot proporcion√≥ informaci√≥n espec√≠fica")
    elif metrics['resolution_rate'] >= 60:
        print("   ‚úì BUENO - La mayor√≠a de respuestas fueron espec√≠ficas")
    elif metrics['resolution_rate'] >= 40:
        print("   ‚ö†Ô∏è  REGULAR - Algunas respuestas fueron vagas")
    else:
        print("   ‚ùå BAJO - El bot necesita m√°s datos espec√≠ficos")
    
    # M√âTRICA 3: PRECISI√ìN Y COMPLETITUD (La Explicaci√≥n)
    print("\n" + "‚îÄ"*70)
    print("3Ô∏è‚É£  PRECISI√ìN Y COMPLETITUD")
    print("‚îÄ"*70)
    print(f"\n   Longitud promedio de respuestas: {metrics['avg_response_length']:.0f} caracteres")
    print(f"   Densidad de informaci√≥n: {metrics['keyword_density']:.1f} datos espec√≠ficos por respuesta")
    print(f"   Nivel de Completitud: {metrics['completitud']}")
    
    if metrics['completitud'] == "EXCELENTE":
        print("   ‚úÖ Las respuestas incluyen m√∫ltiples datos concretos (precios, plazos, etc.)")
    elif metrics['completitud'] == "BUENA":
        print("   ‚úì Las respuestas incluyen datos espec√≠ficos relevantes")
    elif metrics['completitud'] == "REGULAR":
        print("   ‚ö†Ô∏è  Las respuestas podr√≠an ser m√°s espec√≠ficas")
    else:
        print("   ‚ùå Las respuestas carecen de datos concretos")
    
    # M√âTRICA 4: EVOLUCI√ìN DEL SISTEMA (Nueva m√©trica de aprendizaje global)
    evolution = get_system_evolution_metrics()
    print("\n" + "‚îÄ"*70)
    print("4Ô∏è‚É£  EVOLUCI√ìN DEL SISTEMA (Aprendizaje Global)")
    print("‚îÄ"*70)
    print(f"\n   Reglas aprendidas de todos los usuarios: {evolution['total_rules']}")
    print(f"   Usuarios que han contribuido: {evolution['total_users']}")
    print(f"   Memorias acumuladas: {evolution['total_memories']}")
    
    # An√°lisis de errores por categor√≠a
    if evolution['error_distribution']:
        print(f"\n   Distribuci√≥n de Errores Categorizados:")
        for category, count in evolution['error_distribution'].items():
            print(f"      - {category}: {count} reglas")
    
    # Score de validaci√≥n promedio
    if evolution['avg_validation_score'] > 0:
        print(f"\n   Score Promedio de Validaci√≥n: {evolution['avg_validation_score']:.2f}/1.0")
        if evolution['avg_validation_score'] >= 0.8:
            print("      ‚úì Las reglas generadas son altamente efectivas")
        elif evolution['avg_validation_score'] >= 0.5:
            print("      ‚úì Las reglas generadas son moderadamente efectivas")
        else:
            print("      ‚ö†Ô∏è Las reglas necesitan mejorar su efectividad")
    
    # Calcular nivel de madurez del sistema
    maturity_score = min(100, (evolution['total_rules'] * 10) + (evolution['total_memories'] * 2))
    
    print(f"\n   Nivel de Madurez del Sistema: {maturity_score:.0f}/100")
    
    # Barra de madurez
    bar_length = 30
    filled = int((maturity_score / 100) * bar_length)
    bar = "#" * filled + "-" * (bar_length - filled)
    print(f"   [{bar}] {maturity_score:.0f}%")
    
    if maturity_score >= 80:
        print("   >>> SISTEMA MADURO - El bot ha aprendido mucho de los usuarios")
    elif maturity_score >= 50:
        print("   >>> SISTEMA EN CRECIMIENTO - Aprendiendo activamente")
    elif maturity_score >= 20:
        print("   >>> SISTEMA INICIAL - Comenzando a aprender")
    else:
        print("   >>> SISTEMA NUEVO - Primeras interacciones")
    
    print("\n" + "="*70)
    print("Fin del Reporte de M√©tricas")
    print("="*70 + "\n")


def build_system_prompt(user_id):
    """
    Construye el prompt del sistema combinando:
    - PROMPT_BASE (instrucciones base)
    - Reglas de la BD
    - Memoria del usuario
    """
    PROMPT_BASE = """Eres un asistente virtual experto de Kavak, la plataforma l√≠der de compra y venta de autos seminuevos en Latinoam√©rica.

SIEMPRE proporciona informaci√≥n ESPEC√çFICA, DETALLADA y con DATOS CONCRETOS. Nunca des respuestas vagas o gen√©ricas.

INFORMACI√ìN CORPORATIVA:
- Fundada en 2016 en M√©xico
- Presencia en 7 pa√≠ses: M√©xico, Argentina, Chile, Brasil, Colombia, Per√∫ y Turqu√≠a
- M√°s de 20 centros de distribuci√≥n (Hubs)
- Inventario de +10,000 autos disponibles
- +300,000 autos vendidos desde fundaci√≥n

1. COMPRA DE AUTOS - DATOS ESPEC√çFICOS:

INVENTARIO:
- Marcas: Nissan, VW, Chevrolet, Toyota, Honda, Mazda, Ford, Hyundai, KIA, Seat
- Modelos populares: Versa, Jetta, Aveo, Vento, Sentra, March, Corolla, Civic, Mazda 3
- Precios: $120,000 - $800,000 MXN
- A√±os: 2015-2022 t√≠picamente
- Kilometraje: 30,000 - 120,000 km

PROCESO (7 PASOS):
1. B√∫squeda online con filtros
2. Agenda prueba de manejo (sin compromiso)
3. Revisi√≥n del auto (inspecci√≥n 240 puntos)
4. Simulaci√≥n de cr√©dito (respuesta en 5 min)
5. Apartado con $5,000 MXN (reembolsable en 7 d√≠as)
6. Firma de contrato (digital o presencial)
7. Entrega mismo d√≠a o a domicilio (gratis)

BENEFICIOS:
- Garant√≠a mec√°nica: 3 meses o 3,000 km
- Garant√≠a de satisfacci√≥n: 7 d√≠as devoluci√≥n sin preguntas
- Entrega a domicilio sin costo
- Tr√°mites incluidos: placas, tenencia, verificaci√≥n
- Seguro incluido primer mes (cobertura amplia)

2. VENTA DE AUTOS - PROCESO DETALLADO:

PASOS (6 ETAPAS):
1. Cotizaci√≥n online (2 minutos): marca, modelo, a√±o, km
2. Valuaci√≥n inicial: rango de precio inmediato
3. Inspecci√≥n f√≠sica en Hub (30-45 min)
4. Oferta final al terminar inspecci√≥n
5. Pago en 24-48 horas si aceptas
6. Kavak hace todos los tr√°mites

CRITERIOS:
- A√±os: 2010 en adelante generalmente
- Kilometraje m√°ximo: 200,000 km
- Documentos: factura, tarjeta circulaci√≥n, verificaciones
- NO aceptamos: adeudos, robados, da√±os estructurales graves

PAGO:
- Transferencia SPEI: 24-48 hrs
- Cheque certificado: mismo d√≠a
- Efectivo: solo hasta $100,000 MXN

3. FINANCIAMIENTO - INFORMACI√ìN PRECISA:

OPCIONES:
- Enganche desde: 10% del valor
- Plazos: 12, 24, 36, 48, 60 meses
- Tasa anual: 12.9% - 24.9% (seg√∫n perfil)
- Monto m√°ximo: $600,000 MXN
- Comisi√≥n apertura: 3% del monto

REQUISITOS:
- Edad: 18-70 a√±os
- Ingresos m√≠nimos: $8,000 MXN/mes comprobables
- Antig√ºedad laboral: 6 meses m√≠nimo
- Score bur√≥: m√≠nimo 550
- Docs: INE, comprobante domicilio, 3 √∫ltimos recibos

APROBACI√ìN:
- Pre-aprobaci√≥n: 5 minutos online
- An√°lisis: 24-48 horas
- Alianzas: Santander, BBVA, Scotiabank, Cr√©dito Kavak

4. GARANT√çA MEC√ÅNICA (3 MESES/3,000 KM):

CUBRE:
- Motor: bloque, cig√ºe√±al, pistones, bielas, v√°lvulas
- Transmisi√≥n: caja completa (manual/autom√°tica)
- Sistema el√©ctrico: alternador, marcha, computadora
- Direcci√≥n: caja, bomba hidr√°ulica
- Suspensi√≥n: amortiguadores, brazos
- Frenos: bomba, booster

NO CUBRE:
- Desgaste normal: balatas, llantas, filtros
- Da√±os por mal uso o accidentes
- Mantenimiento preventivo

C√ìMO USAR GARANT√çA:
1. Llama al 800-KAVAK-01
2. Describe el problema
3. Agenda cita en taller autorizado
4. Kavak cubre reparaci√≥n si aplica

5. INSPECCI√ìN 240 PUNTOS:

CATEGOR√çAS:
- Motor (40 puntos): compresi√≥n, fugas, ruidos
- Transmisi√≥n (25 puntos): cambios, sincronizaci√≥n
- Frenos (20 puntos): discos, balatas, l√≠quido
- Suspensi√≥n (25 puntos): amortiguadores, r√≥tulas
- El√©ctrico (30 puntos): bater√≠a, luces, sensores
- Carrocer√≠a (40 puntos): pintura, abolladuras, √≥xido
- Interior (30 puntos): asientos, tablero, clima
- Documentaci√≥n (30 puntos): factura, adeudos, historial

PROCESO:
- Duraci√≥n: 2-3 horas por auto
- Mec√°nicos certificados
- Reporte digital disponible para cada auto
- Solo pasan autos en buen estado (70% rechazados)

INSTRUCCIONES CR√çTICAS:
- SIEMPRE menciona n√∫meros, plazos, montos espec√≠ficos
- NUNCA digas solo "tenemos garant√≠as" - especifica 3 meses/3,000 km
- NUNCA digas "varios modelos" - menciona marcas y modelos concretos
- Si preguntan por precio, da rangos reales ($120k-$800k MXN)
- Si preguntan por financiamiento, menciona tasas (12.9%-24.9%)
- S√© amigable pero SIEMPRE con datos concretos
- Si no sabes algo MUY espec√≠fico, ofrece conectar con asesor"""

    # Obtener reglas y memoria
    rules = get_all_rules()
    memory = get_user_memory(user_id)
    
    # Combinar todo en el prompt final
    final_prompt = PROMPT_BASE
    
    if rules:
        final_prompt += f"\n\nREGLAS ADICIONALES:\n{rules}"
    
    if memory:
        final_prompt += f"\n\n{memory}"
    
    return final_prompt


def main():
    """
    Bucle principal del chatbot en consola.
    """
    print("=" * 60)
    print("üöó BIENVENIDO AL ASISTENTE VIRTUAL DE KAVAK üöó")
    print("=" * 60)
    print("\nEscribe 'salir' en cualquier momento para terminar la conversaci√≥n.\n")
    
    # Solicitar user_id (simulaci√≥n de login)
    user_id = input("Por favor, ingresa tu ID de usuario: ").strip()
    
    if not user_id:
        print("‚ùå Error: Debes ingresar un ID de usuario v√°lido.")
        return
    
    print(f"\n‚úÖ Sesi√≥n iniciada para usuario: {user_id}")
    print("\nCargando asistente...")
    
    # Configurar clientes HTTP (s√≠ncrono y as√≠ncrono) con timeout personalizado
    sync_client = httpx.Client(timeout=30.0)
    async_client = httpx.AsyncClient(timeout=30.0)
    
    # Inicializar el LLM con clientes HTTP personalizados
    llm = ChatOpenAI(
        model="gpt-3.5-turbo", 
        temperature=0.7,
        http_client=sync_client,
        http_async_client=async_client
    )
    
    # Construir el prompt del sistema
    system_prompt = build_system_prompt(user_id)
    
    # Inicializar historial de chat
    chat_history = [SystemMessage(content=system_prompt)]
    
    print("\n" + "=" * 60)
    print("Puedes empezar a chatear con el asistente de Kavak")
    print("=" * 60)
    
    # Bucle principal de conversaci√≥n
    while True:
        # Obtener input del usuario
        user_input = input("\nüßë T√∫: ").strip()
        
        # Verificar comando de salida
        if user_input.lower() == 'salir':
            # Aprendizaje autom√°tico de la conversaci√≥n
            if len(chat_history) > 1:
                print("\n" + "="*70)
                print("Analizando conversaci√≥n y aprendiendo autom√°ticamente...")
                print("="*70)
                
                # APRENDIZAJE AUTOM√ÅTICO (sin intervenci√≥n del usuario)
                auto_learn_from_conversation(chat_history, user_id, llm)
                
                # Calcular y mostrar m√©tricas
                print("\nGenerando reporte de m√©tricas...\n")
                metrics = calculate_metrics(chat_history)
                display_metrics(metrics)
            
            print("\nüëã ¬°Gracias por usar el asistente de Kavak! Hasta pronto.")
            break
        
        # Validar que el input no est√© vac√≠o
        if not user_input:
            print("‚ö†Ô∏è  Por favor, escribe algo.")
            continue
        
        # A√±adir mensaje del usuario al historial
        chat_history.append(HumanMessage(content=user_input))
        
        # Mostrar mensaje de espera
        print("\nü§ñ Kavak pensando...")
        
        try:
            # Llamar a la IA
            response = llm.invoke(chat_history)
            ai_response_content = response.content
            
            # Mostrar respuesta
            print(f"\nüöó Kavak: {ai_response_content}")
            
            # A√±adir respuesta del bot al historial para mantener contexto
            chat_history.append(AIMessage(content=ai_response_content))
            
            # Sistema de feedback OPCIONAL (el aprendizaje real es autom√°tico al salir)
            print("\n¬øQuieres dar feedback? (si/no para forzar aprendizaje, Enter para continuar)")
            feedback = input("Tu feedback: ").strip().lower()
            
            if feedback == 'si' or feedback == 's':
                save_user_memory(user_id, chat_history, llm)
            elif feedback == 'no' or feedback == 'n':
                optimize_prompt_rule(chat_history, llm)
                # Reconstruir el prompt con la nueva regla para mejorar en esta misma conversaci√≥n
                print("\n[Sistema: Aplicando mejora al asistente...]")
                system_prompt = build_system_prompt(user_id)
                # Actualizar el system message en el historial
                chat_history[0] = SystemMessage(content=system_prompt)
                print("[Sistema: ‚úì Asistente mejorado. Continuemos...]")
            elif feedback == '' or feedback == 'siguiente':
                pass  # Continuar - el aprendizaje real ocurre autom√°ticamente al salir
            else:
                pass  # Continuar
            
        except Exception as e:
            print(f"\n‚ùå Error al comunicarse con la IA: {str(e)}")
            print("Por favor, verifica tu configuraci√≥n de API key en el archivo .env")
            break


if __name__ == "__main__":
    main()
